"""
ç‹¬ç«‹çš„Flaskéƒ¨ç½²æœåŠ¡
ç”¨äºéƒ¨ç½²æ¨¡å‹å¹¶æä¾›æ¨ç†æ¥å£
æ”¯æŒNacosæ³¨å†Œã€æ—¥å¿—ä¸ŠæŠ¥ã€åœæ­¢/é‡å¯æ¥å£
"""
import os
import sys
import time
import threading
import logging
import uuid
import socket
import requests
import atexit
import signal
from datetime import datetime
from flask import Flask, request, jsonify
from flask_cors import CORS

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å‹ç›¸å…³ä»£ç 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æ¨ç†ç›¸å…³æ¨¡å—
ONNXInference = None
try:
    from app.utils.onnx_inference import ONNXInference
    from app.utils.yolo_validator import validate_yolo_model
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥æ¨ç†æ¨¡å—: {e}")

app = Flask(__name__)
CORS(app)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
model = None
model_loaded = False
service_id = None
service_name = None
model_id = None
model_version = None
model_format = None
nacos_service_name = None  # Nacosæ³¨å†Œçš„æœåŠ¡å
server_ip = None
port = None
ai_service_api = None
heartbeat_thread = None
heartbeat_stop_event = threading.Event()
log_report_thread = None
log_report_stop_event = threading.Event()
nacos_client = None
shutdown_flag = threading.Event()


def get_mac_address():
    """è·å–MACåœ°å€"""
    try:
        mac = uuid.getnode()
        return ':'.join(['{:02x}'.format((mac >> elements) & 0xff) for elements in range(0, 2 * 6, 2)][::-1])
    except:
        return 'unknown'


def get_local_ip():
    """è·å–æœ¬åœ°IPåœ°å€"""
    # æ–¹æ¡ˆ1: ç¯å¢ƒå˜é‡ä¼˜å…ˆ
    if ip := os.getenv('POD_IP'):
        return ip
    
    # æ–¹æ¡ˆ2: å¤šç½‘å¡æ¢æµ‹
    try:
        import netifaces
        for iface in netifaces.interfaces():
            addrs = netifaces.ifaddresses(iface).get(netifaces.AF_INET, [])
            for addr in addrs:
                ip = addr['addr']
                if ip != '127.0.0.1' and not ip.startswith('169.254.'):
                    return ip
    except:
        pass
    
    # æ–¹æ¡ˆ3: åŸå§‹æ–¹å¼
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except:
        return '127.0.0.1'


def get_ai_module_instance():
    """ä»Nacosè·å–AIæ¨¡å—å®ä¾‹åˆ—è¡¨ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª"""
    global nacos_client
    
    try:
        if not nacos_client:
            # å¦‚æœNacoså®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œå°è¯•åˆå§‹åŒ–
            from nacos import NacosClient
            nacos_server = os.getenv('NACOS_SERVER', 'localhost:8848')
            namespace = os.getenv('NACOS_NAMESPACE', '')
            username = os.getenv('NACOS_USERNAME', 'nacos')
            password = os.getenv('NACOS_PASSWORD', 'basiclab@iot78475418754')
            
            nacos_client = NacosClient(
                server_addresses=nacos_server,
                namespace=namespace,
                username=username,
                password=password
            )
        
        # AIæ¨¡å—çš„æœåŠ¡åï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼Œé»˜è®¤æ˜¯model-serverï¼‰
        ai_service_name = os.getenv('AI_SERVICE_NAME', 'model-server')
        
        # è·å–æœåŠ¡å®ä¾‹åˆ—è¡¨
        instances = nacos_client.list_naming_instance(
            service_name=ai_service_name,
            healthy_only=True
        )
        
        if not instances or len(instances) == 0:
            logger.warning(f"æœªæ‰¾åˆ°AIæ¨¡å—å®ä¾‹: {ai_service_name}")
            return None
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªå®ä¾‹
        import random
        selected_instance = random.choice(instances)
        
        # æ„å»ºURL
        ip = selected_instance.get('ip', '')
        port = selected_instance.get('port', 5000)
        ai_url = f"http://{ip}:{port}"
        
        logger.info(f"ä»Nacosè·å–åˆ°AIæ¨¡å—å®ä¾‹: {ai_url} (å…±{len(instances)}ä¸ªå®ä¾‹)")
        return ai_url
        
    except Exception as e:
        logger.error(f"ä»Nacosè·å–AIæ¨¡å—å®ä¾‹å¤±è´¥: {str(e)}")
        # å¦‚æœNacosè·å–å¤±è´¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„é»˜è®¤å€¼
        default_ai_url = os.getenv('AI_SERVICE_API', 'http://localhost:5000')
        logger.warning(f"ä½¿ç”¨é»˜è®¤AIæ¨¡å—åœ°å€: {default_ai_url}")
        return default_ai_url


def load_model(model_path):
    """åŠ è½½æ¨¡å‹"""
    global model, model_loaded
    
    try:
        logger.info(f"å¼€å§‹åŠ è½½æ¨¡å‹: {model_path}")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ¨¡å‹ç±»å‹
        if model_path.endswith('.onnx'):
            # ONNXæ¨¡å‹åŠ è½½
            try:
                model = ONNXInference(model_path)
                logger.info("ONNXæ¨¡å‹åŠ è½½æˆåŠŸ")
                model_loaded = True
                return True
            except ImportError:
                logger.error("onnxruntimeæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½ONNXæ¨¡å‹")
                return False
            except Exception as e:
                logger.error(f"ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                return False
        else:
            # PyTorchæ¨¡å‹åŠ è½½ï¼ˆ.ptæ–‡ä»¶ï¼‰
            try:
                from ultralytics import YOLO
                model = YOLO(model_path)
                logger.info("YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
                model_loaded = True
                return True
            except Exception as e:
                logger.error(f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                return False
        
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        model_loaded = False
        return False


def send_heartbeat():
    """å‘é€å¿ƒè·³åˆ°ä¸»ç¨‹åºï¼ˆé€šè¿‡Nacosè·å–AIæ¨¡å—å®ä¾‹ï¼‰"""
    global service_id, service_name, server_ip, port, model_id, model_version, model_format
    
    while not heartbeat_stop_event.is_set():
        try:
            # ä»Nacosè·å–AIæ¨¡å—å®ä¾‹
            ai_service_api = get_ai_module_instance()
            
            if ai_service_api:
                data = {
                    'server_ip': server_ip,
                    'port': port,
                    'inference_endpoint': f"http://{server_ip}:{port}/inference",
                    'mac_address': get_mac_address()
                }
                
                if service_name:
                    data['service_name'] = service_name
                if service_id:
                    data['service_id'] = service_id
                if model_id:
                    data['model_id'] = model_id
                if model_version:
                    data['model_version'] = model_version
                if model_format:
                    data['format'] = model_format
                
                try:
                    response = requests.post(
                        f"{ai_service_api}/model/deploy_service/heartbeat",
                        json=data,
                        timeout=5
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        if result.get('code') == 0 and result.get('data'):
                            returned_service_id = result.get('data', {}).get('service_id')
                            if returned_service_id:
                                service_id = returned_service_id
                        logger.debug("å¿ƒè·³å‘é€æˆåŠŸ")
                    else:
                        logger.warning(f"å¿ƒè·³å‘é€å¤±è´¥: {response.status_code}")
                except requests.exceptions.RequestException as e:
                    logger.warning(f"å¿ƒè·³å‘é€è¯·æ±‚å¼‚å¸¸: {str(e)}")
                    
        except Exception as e:
            logger.error(f"å¿ƒè·³å‘é€å¼‚å¸¸: {str(e)}")
        
        time.sleep(30)  # æ¯30ç§’å‘é€ä¸€æ¬¡å¿ƒè·³


def send_log_to_main(log_content, log_level='INFO'):
    """ä¸ŠæŠ¥æ—¥å¿—åˆ°ä¸»ç¨‹åºï¼ˆé€šè¿‡Nacosè·å–AIæ¨¡å—å®ä¾‹ï¼‰"""
    global service_name
    
    try:
        # ä»Nacosè·å–AIæ¨¡å—å®ä¾‹
        ai_service_api = get_ai_module_instance()
        
        if not ai_service_api:
            return
        
        # æ„å»ºæ—¥å¿—ä¸ŠæŠ¥æ•°æ®
        log_data = {
            'service_name': service_name,
            'log': log_content,
            'level': log_level,
            'timestamp': datetime.now().isoformat()
        }
        
        # å‘é€æ—¥å¿—åˆ°ä¸»ç¨‹åº
        try:
            response = requests.post(
                f"{ai_service_api}/model/deploy_service/logs",
                json=log_data,
                timeout=3
            )
            if response.status_code == 200:
                logger.debug("æ—¥å¿—ä¸ŠæŠ¥æˆåŠŸ")
        except requests.exceptions.RequestException:
            # å¦‚æœæ—¥å¿—ä¸ŠæŠ¥æ¥å£ä¸å­˜åœ¨ï¼Œé™é»˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰
            pass
            
    except Exception as e:
        logger.debug(f"æ—¥å¿—ä¸ŠæŠ¥å¼‚å¸¸: {str(e)}")


class LogHandler(logging.Handler):
    """è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œç”¨äºä¸ŠæŠ¥æ—¥å¿—åˆ°ä¸»ç¨‹åº"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._last_send_time = 0
        self._log_buffer = []
        self._buffer_lock = threading.Lock()
        self._buffer_size = 10  # ç¼“å†²åŒºå¤§å°
        self._flush_interval = 5  # åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰
        
        # å¯åŠ¨åå°çº¿ç¨‹å®šæœŸåˆ·æ–°ç¼“å†²åŒº
        self._flush_thread = threading.Thread(target=self._periodic_flush, daemon=True)
        self._flush_thread.start()
    
    def emit(self, record):
        """å‘é€æ—¥å¿—è®°å½•"""
        try:
            log_message = self.format(record)
            log_level = record.levelname
            
            # å°†æ—¥å¿—æ·»åŠ åˆ°ç¼“å†²åŒº
            with self._buffer_lock:
                self._log_buffer.append({
                    'message': log_message,
                    'level': log_level,
                    'timestamp': datetime.now().isoformat()
                })
                
                # å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œç«‹å³åˆ·æ–°
                if len(self._log_buffer) >= self._buffer_size:
                    self._flush_buffer()
        except Exception:
            pass  # é¿å…æ—¥å¿—ä¸ŠæŠ¥å¤±è´¥å½±å“ä¸»æµç¨‹
    
    def _flush_buffer(self):
        """åˆ·æ–°ç¼“å†²åŒºï¼Œä¸ŠæŠ¥æ‰€æœ‰æ—¥å¿—"""
        with self._buffer_lock:
            if not self._log_buffer:
                return
            
            # æ‰¹é‡ä¸ŠæŠ¥æ—¥å¿—
            for log_item in self._log_buffer:
                send_log_to_main(log_item['message'], log_item['level'])
            
            self._log_buffer.clear()
    
    def _periodic_flush(self):
        """å®šæœŸåˆ·æ–°ç¼“å†²åŒº"""
        while not log_report_stop_event.is_set():
            time.sleep(self._flush_interval)
            self._flush_buffer()
    
    def close(self):
        """å…³é—­å¤„ç†å™¨æ—¶åˆ·æ–°ç¼“å†²åŒº"""
        self._flush_buffer()
        super().close()


def setup_nacos():
    """è®¾ç½®Nacosæ³¨å†Œ"""
    global nacos_client, nacos_service_name, server_ip, port, model_id, model_version, model_format
    
    try:
        from nacos import NacosClient
        
        # è·å–Nacosé…ç½®
        nacos_server = os.getenv('NACOS_SERVER', 'localhost:8848')
        namespace = os.getenv('NACOS_NAMESPACE', '')
        username = os.getenv('NACOS_USERNAME', 'nacos')
        password = os.getenv('NACOS_PASSWORD', 'basiclab@iot78475418754')
        
        # åˆ›å»ºNacoså®¢æˆ·ç«¯
        nacos_client = NacosClient(
            server_addresses=nacos_server,
            namespace=namespace,
            username=username,
            password=password
        )
        
        # æ„å»ºNacosæœåŠ¡åï¼šmodel_{model_id}_{format}_{version}
        if model_id and model_version and model_format:
            nacos_service_name = f"model_{model_id}_{model_format}_{model_version}"
        else:
            # å¦‚æœç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œä½¿ç”¨service_nameä½œä¸ºfallback
            logger.warning("ç¼ºå°‘model_id/model_version/model_formatï¼Œä½¿ç”¨service_nameä½œä¸ºNacosæœåŠ¡å")
            nacos_service_name = service_name
        
        # æ³¨å†ŒæœåŠ¡å®ä¾‹
        nacos_client.add_naming_instance(
            service_name=nacos_service_name,
            ip=server_ip,
            port=port,
            cluster_name="DEFAULT",
            healthy=True,
            ephemeral=True
        )
        
        logger.info(f"âœ… æœåŠ¡æ³¨å†Œåˆ°NacosæˆåŠŸ: {nacos_service_name}@{server_ip}:{port}")
        return True
        
    except ImportError:
        logger.warning("nacos-sdk-pythonæœªå®‰è£…ï¼Œè·³è¿‡Nacosæ³¨å†Œ")
        return False
    except Exception as e:
        logger.error(f"Nacosæ³¨å†Œå¤±è´¥: {str(e)}")
        return False


def send_nacos_heartbeat():
    """å‘é€Nacoså¿ƒè·³"""
    global nacos_client, nacos_service_name, server_ip, port
    
    while not heartbeat_stop_event.is_set():
        try:
            if nacos_client and nacos_service_name:
                nacos_client.send_heartbeat(
                    service_name=nacos_service_name,
                    ip=server_ip,
                    port=port
                )
        except Exception as e:
            logger.error(f"Nacoså¿ƒè·³å‘é€å¼‚å¸¸: {str(e)}")
        
        time.sleep(5)  # æ¯5ç§’å‘é€ä¸€æ¬¡Nacoså¿ƒè·³


def deregister_nacos():
    """æ³¨é”€NacosæœåŠ¡"""
    global nacos_client, nacos_service_name, server_ip, port
    
    try:
        if nacos_client and nacos_service_name:
            nacos_client.remove_naming_instance(
                service_name=nacos_service_name,
                ip=server_ip,
                port=port
            )
            logger.info(f"ğŸ”´ NacosæœåŠ¡æ³¨é”€æˆåŠŸ: {nacos_service_name}@{server_ip}:{port}")
    except Exception as e:
        logger.error(f"Nacosæ³¨é”€å¼‚å¸¸: {str(e)}")


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_loaded,
        'service_id': service_id,
        'service_name': service_name
    })


@app.route('/inference', methods=['POST'])
def inference():
    """æ¨ç†æ¥å£"""
    global model, model_loaded
    
    if not model_loaded or model is None:
        return jsonify({
            'code': 500,
            'msg': 'æ¨¡å‹æœªåŠ è½½'
        }), 500
    
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸Šä¼ 
        if 'file' not in request.files:
            return jsonify({
                'code': 400,
                'msg': 'æœªæ‰¾åˆ°æ–‡ä»¶'
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'code': 400,
                'msg': 'æœªé€‰æ‹©æ–‡ä»¶'
            }), 400
        
        # è·å–æ¨ç†å‚æ•°
        conf_thres = float(request.form.get('conf_thres', 0.25))
        iou_thres = float(request.form.get('iou_thres', 0.45))
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1])
        file.save(temp_file.name)
        temp_file.close()
        
        try:
            # æ‰§è¡Œæ¨ç†
            # æ£€æŸ¥æ˜¯å¦ä¸ºONNXæ¨¡å‹
            is_onnx = False
            if ONNXInference is not None:
                is_onnx = isinstance(model, ONNXInference)
            else:
                # å¦‚æœONNXInferenceæœªå¯¼å…¥ï¼Œæ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰detectæ–¹æ³•ä¸”æ²¡æœ‰predictæ–¹æ³•
                is_onnx = hasattr(model, 'detect') and not hasattr(model, 'predict')
            
            if is_onnx:
                # ONNXæ¨¡å‹æ¨ç†
                output_image, detections = model.detect(
                    temp_file.name,
                    conf_threshold=conf_thres,
                    iou_threshold=iou_thres,
                    draw=True
                )
                
                # ä¿å­˜ç»“æœå›¾ç‰‡
                import cv2
                result_path = temp_file.name.replace(os.path.splitext(temp_file.name)[1], '_result.jpg')
                cv2.imwrite(result_path, output_image)
                
                return jsonify({
                    'code': 0,
                    'msg': 'æ¨ç†æˆåŠŸ',
                    'data': {
                        'predictions': detections,
                        'result_image_path': result_path
                    }
                })
            elif hasattr(model, 'predict'):  # YOLOæ¨¡å‹
                results = model.predict(
                    temp_file.name,
                    conf=conf_thres,
                    iou=iou_thres,
                    verbose=False
                )
                
                # å¤„ç†ç»“æœ
                predictions = []
                for result in results:
                    boxes = result.boxes
                    for box in boxes:
                        predictions.append({
                            'class': int(box.cls.item()),
                            'class_name': result.names[int(box.cls.item())],
                            'confidence': float(box.conf.item()),
                            'bbox': box.xyxy.tolist()[0]
                        })
                
                # ä¿å­˜ç»“æœå›¾ç‰‡
                result_path = temp_file.name.replace(os.path.splitext(temp_file.name)[1], '_result.jpg')
                results[0].save(filename=result_path)
                
                return jsonify({
                    'code': 0,
                    'msg': 'æ¨ç†æˆåŠŸ',
                    'data': {
                        'predictions': predictions,
                        'result_image_path': result_path
                    }
                })
            else:
                return jsonify({
                    'code': 500,
                    'msg': 'ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹'
                }), 500
                
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(temp_file.name):
                    os.unlink(temp_file.name)
            except:
                pass
                
    except Exception as e:
        logger.error(f"æ¨ç†å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'msg': f'æ¨ç†å¤±è´¥: {str(e)}'
        }), 500


@app.route('/stop', methods=['POST'])
def stop_service():
    """åœæ­¢æœåŠ¡æ¥å£"""
    global shutdown_flag
    
    try:
        logger.info("æ”¶åˆ°åœæ­¢æœåŠ¡è¯·æ±‚")
        shutdown_flag.set()
        
        # åœæ­¢å¿ƒè·³çº¿ç¨‹
        heartbeat_stop_event.set()
        
        # åœæ­¢æ—¥å¿—ä¸ŠæŠ¥
        log_report_stop_event.set()
        
        # æ³¨é”€Nacos
        deregister_nacos()
        
        # å»¶è¿Ÿå…³é—­ï¼Œç»™å“åº”æ—¶é—´
        def delayed_shutdown():
            time.sleep(1)
            os._exit(0)
        
        threading.Thread(target=delayed_shutdown, daemon=True).start()
        
        return jsonify({
            'code': 0,
            'msg': 'æœåŠ¡æ­£åœ¨åœæ­¢'
        })
    except Exception as e:
        logger.error(f"åœæ­¢æœåŠ¡å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'msg': f'åœæ­¢æœåŠ¡å¤±è´¥: {str(e)}'
        }), 500


@app.route('/restart', methods=['POST'])
def restart_service():
    """é‡å¯æœåŠ¡æ¥å£"""
    global model, model_loaded, model_id
    
    try:
        logger.info("æ”¶åˆ°é‡å¯æœåŠ¡è¯·æ±‚")
        
        # é‡æ–°åŠ è½½æ¨¡å‹
        model_path = os.getenv('MODEL_PATH')
        if model_path:
            model_loaded = False
            model = None
            if load_model(model_path):
                return jsonify({
                    'code': 0,
                    'msg': 'æœåŠ¡é‡å¯æˆåŠŸ'
                })
            else:
                return jsonify({
                    'code': 500,
                    'msg': 'æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥'
                }), 500
        else:
            return jsonify({
                'code': 400,
                'msg': 'MODEL_PATHç¯å¢ƒå˜é‡æœªè®¾ç½®'
            }), 400
            
    except Exception as e:
        logger.error(f"é‡å¯æœåŠ¡å¤±è´¥: {str(e)}")
        return jsonify({
            'code': 500,
            'msg': f'é‡å¯æœåŠ¡å¤±è´¥: {str(e)}'
        }), 500


def main():
    """ä¸»å‡½æ•°"""
    global service_id, service_name, model_id, model_version, model_format, server_ip, port, ai_service_api
    global heartbeat_thread, log_report_thread, nacos_client
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    service_id = os.getenv('SERVICE_ID')
    service_name = os.getenv('SERVICE_NAME', 'deploy_service')
    model_id = os.getenv('MODEL_ID')
    model_version = os.getenv('MODEL_VERSION', 'V1.0.0')
    model_format = os.getenv('MODEL_FORMAT', 'pytorch')  # é»˜è®¤pytorch
    port = int(os.getenv('PORT', 8000))
    model_path = os.getenv('MODEL_PATH')
    # ä¸å†ä½¿ç”¨å›ºå®šçš„ai_service_apiï¼Œæ”¹ä¸ºä»NacosåŠ¨æ€è·å–
    # ai_service_api = os.getenv('AI_SERVICE_API', 'http://localhost:5000/model/deploy_service')
    
    server_ip = get_local_ip()
    
    if not model_path:
        logger.error("MODEL_PATHç¯å¢ƒå˜é‡æœªè®¾ç½®")
        sys.exit(1)
    
    if not service_name:
        logger.error("SERVICE_NAMEç¯å¢ƒå˜é‡æœªè®¾ç½®")
        sys.exit(1)
    
    # æ·»åŠ æ—¥å¿—å¤„ç†å™¨ï¼Œç”¨äºä¸ŠæŠ¥æ—¥å¿—åˆ°ä¸»ç¨‹åº
    log_handler = LogHandler()
    log_handler.setLevel(logging.INFO)
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    log_handler.setFormatter(formatter)
    logger.addHandler(log_handler)
    
    # ç¡®ä¿åœ¨ç¨‹åºé€€å‡ºæ—¶å…³é—­æ—¥å¿—å¤„ç†å™¨
    def cleanup_log_handler():
        log_handler.close()
    atexit.register(cleanup_log_handler)
    
    # åŠ è½½æ¨¡å‹
    if not load_model(model_path):
        logger.error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œé€€å‡º")
        sys.exit(1)
    
    # æ³¨å†Œåˆ°Nacos
    setup_nacos()
    
    # å¯åŠ¨å¿ƒè·³çº¿ç¨‹ï¼ˆå‘é€åˆ°ä¸»ç¨‹åºï¼‰
    heartbeat_thread = threading.Thread(target=send_heartbeat, daemon=True)
    heartbeat_thread.start()
    logger.info("å¿ƒè·³çº¿ç¨‹å·²å¯åŠ¨")
    
    # å¯åŠ¨Nacoså¿ƒè·³çº¿ç¨‹
    if nacos_client:
        nacos_heartbeat_thread = threading.Thread(target=send_nacos_heartbeat, daemon=True)
        nacos_heartbeat_thread.start()
        logger.info("Nacoså¿ƒè·³çº¿ç¨‹å·²å¯åŠ¨")
    
    # æ³¨å†Œé€€å‡ºå¤„ç†
    atexit.register(deregister_nacos)
    
    # æ³¨å†Œä¿¡å·å¤„ç†
    def signal_handler(signum, frame):
        logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
        deregister_nacos()
        sys.exit(0)
    
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # å¯åŠ¨FlaskæœåŠ¡
    logger.info(f"éƒ¨ç½²æœåŠ¡å¯åŠ¨: {service_name} on {server_ip}:{port}")
    try:
        app.run(host='0.0.0.0', port=port, threaded=True)
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
        deregister_nacos()
        sys.exit(0)


if __name__ == '__main__':
    main()
